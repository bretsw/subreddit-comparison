---
title: "For the Longest Time: Continuity and Change in One Teaching-Related Subreddit"
author: "K. Bret Staudt Willet & Jeffrey P. Carpenter"
date: "12/12/2019"
output:
  pdf_document:
    toc: yes
  html_document:
    float_toc: yes
    toc: yes
---

# Get set up

This section loads the data and packages and starts to process the data, but doesn't calculate any statistics or create any results.

1. Load packages

```{r, include=FALSE}
library(knitr)
library(tidyverse)  # for data manipulation
library(anytime)
library(lubridate)  # for working with dates
library(igraph)  # for processing the social network
library(ggraph)  # for visualizing the social network
```

2. Set up settings for sharing 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
usethis::use_git_ignore(c("*.csv", "*.rds"))
```

3. Set timeframe

```{r timeframe, include=FALSE}
date_start <- as_datetime("2016-01-01 05:00:00 UTC") %>% 
        ymd_hms() %>%
        with_tz(tzone="US/Eastern")
date_end <- as_datetime("2019-07-1 03:59:59 UTC") %>% 
        ymd_hms() %>%
        with_tz(tzone="US/Eastern")
```

4. Load subreddit posts

```{r posts, include=FALSE}
posts <- read.csv("data/r-education-posts.csv", 
                            header=TRUE, 
                            colClasses='character'
                            ) %>%
        as.data.frame() %>%
        rename(post_id = id, 
               post_author = author,
               post_voting_score = score,
               post_text = selftext
               ) %>%
        mutate(post_date_time = created_utc %>% 
                       as.numeric() %>% 
                       anytime(asUTC=TRUE) %>% 
                       as_datetime %>%
                       ymd_hms() %>%
                       with_tz(tzone="US/Eastern"),
               post_voting_score = post_voting_score %>% as.numeric(),
               post_year = year(post_date_time),
               post_word_count = str_count(title, "\\s+") + 
                       str_count(post_text, "\\s+") + 2
               ) %>%
        distinct(post_id, .keep_all = TRUE) %>%
        filter(post_date_time >= date_start,
               post_date_time <= date_end,
               post_id != "",
               !is.na(post_id),
               post_author != "",
               post_author != "[deleted]",
               post_text != "[deleted]",
               post_text != "[removed]"
               )
```

5. Load subreddit responses

```{r responses, include=FALSE}
responses <- read.csv("data/r-education-responses.csv", 
                            header=TRUE, 
                            colClasses='character'
                            ) %>%
        as.data.frame() %>% 
        rename(response_id = id, 
               response_author = author,
               response_voting_score = score,
               response_text = body) %>%
        mutate(thread_id = str_remove(link_id, pattern="t[0-9]_"),
               parent_id = str_remove(parent_id, pattern="t[0-9]_"),
               response_date_time = created_utc %>% 
                       as.numeric() %>% 
                       anytime(asUTC=TRUE) %>% 
                       as_datetime %>%
                       ymd_hms() %>%
                       with_tz(tzone="US/Eastern"),
               post_id = thread_id,
               response_voting_score = response_voting_score %>% as.numeric(),
               response_year = year(response_date_time),
               response_word_count = str_count(response_text, "\\s+") + 1
               ) %>% 
        distinct(response_id, .keep_all = TRUE) %>%
        filter(response_date_time >= date_start,
               response_date_time <= date_end,
               response_id != "",
               !is.na(response_id),
               response_author != "",
               response_author != "[deleted]",
               response_text != "[deleted]",
               response_text != "[removed]"
               )
```

6. Create a merged dataframe of both posts and responses.

```{r merged, include=FALSE}
merged <- posts %>% 
        left_join(responses, by=c('post_id')) %>%
        mutate(self_response = ifelse(is.na(response_author), 
                                      FALSE,
                                      ifelse(post_author==response_author, TRUE, FALSE)
                                      )
               ) %>%
        group_by(post_id) %>%
        mutate(n_responses = length(which(!is.na(response_id))),
               n_self_responses = length(which(self_response)), 
               p_self_responses = ifelse(n_responses==0, 
                                         0, 
                                         round(100 * n_self_responses / n_responses, 2)
                                         )
               ) %>%
        ungroup()
```

# Analysis and Results

## Figure 1. Contributions over time

```{r, include=TRUE, echo=FALSE}
n_months <- (date_end - date_start) %>% time_length(unit="months")
n_posts_overall <- length(unique(merged$post_id))
n_responses_overall <- merged %>%
        filter(., !is.na(response_id)) %>%
        pull(response_id) %>%
        unique() %>%
        length()
n_contributions_overall <- n_posts_overall + n_responses_overall
n_posters_overall <- length(unique(merged$post_author))
n_responders_overall <- merged %>%
        filter(., !is.na(response_author)) %>%
        pull(response_author) %>%
        unique() %>%
        length()
n_contributors_overall <- merged %>%
        c(pull(., post_author), pull(., response_author)) %>%
        unique() %>%
        length() -1  ## to account for the NA response_author

paste0("In total, we collected ", n_contributions_overall,  " contributions from ", n_contributors_overall, " contributors"); paste0("dated between ", date(date_start), " and ", date(date_end), " (", round(n_months, 2), " months),"); paste0("a total of ", n_posts_overall, " posts and ", n_responses_overall, " responses to those posts,"); paste0("to one teaching-related subreddit: r/Teachers.")
```

```{r figure1, include=TRUE, echo=FALSE}
to_plot_posts <- posts$post_date_time %>% 
        floor_date("day") %>% 
        as_date() %>%
        table() %>% 
        as.data.frame() %>%
        rename(day = ".",
               n = Freq) %>%
        mutate(day = as_date(day),
               type = "post") %>%
        filter((day >= date_start) & (day <= date_end))
to_plot_responses <- responses$response_date_time %>% 
        floor_date("day") %>% 
        as_date() %>%
        table() %>% 
        as.data.frame() %>%
        rename(day = ".",
               n = Freq) %>%
        mutate(day = as_date(day),
               type = "response") %>%
        filter((day >= date_start) & (day <= date_end))

to_plot <- full_join(to_plot_posts, to_plot_responses, by = c("day", "type", "n")) %>%
        mutate(type = as.factor(type))

ggplot(data = to_plot, mapping = aes(x=day, y=n, color=type)) +
        geom_point(size = 1.5, alpha=.9) + 
        geom_smooth(method='auto', se=FALSE, size=2) +
        scale_y_continuous(trans='log10') +
        xlab(NULL) +
        ylab("Number of Contributions") +
#        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        theme_bw() +
        theme(panel.grid.major = element_line(color = "gray30"),
              panel.grid.minor = element_line(color = "gray90"),
              legend.position='bottom',
              axis.title=element_text(size=28, family='serif'),
              axis.text=element_text(size=24, family='serif'),
              legend.title=element_text(size=28, family='serif'), 
              legend.text=element_text(size=24, family='serif')
              ) +
        labs(color='Type of Contribution:')
```

```{r save-figure, include=FALSE}
#ggsave("contributions-over-time-r-teachers.png", width = 16, height = 9)
```

```{r regression-line, include=TRUE, echo=FALSE}
## Print the slopes of the linear regressions:
post_fit <- to_plot %>% 
        filter(type=='post') %>% 
        lm(n ~ day, data = .)
post_slope <- post_fit$coefficients[[2]] %>% round(2)
post_slope_pval <- summary(post_fit)$coef[2,4] %>% round(8)

response_fit <- to_plot %>% 
        filter(type=='response') %>% 
        lm(n ~ day, data = .)
response_slope <- response_fit$coefficients[[2]] %>% round(2)
response_slope_pval <- summary(response_fit)$coef[2,4] %>% round(8)

paste0("The slope of the `post` linear regression is ", post_slope, " (p=", post_slope_pval, "),"); paste0("and the slope of the `response` linear regression is ", response_slope, " (p=", response_slope_pval, ").")
```

## Table 1. Overall contributions in r/Teachers

```{r table1, include=TRUE, echo=FALSE}
## have to subtract 1 to account for NA rows for n_responders and n_contributors
table1_init <- merged %>%
        group_by(post_year) %>% 
        summarize(n_posters = length(unique(post_author)),
                  n_responders = length(unique(response_author)) - 1, 
                  n_contributors = length(unique(c(post_author, response_author))) - 1
                  )
n_multiple_posts <- merged %>% 
        group_by(post_year) %>% 
        count(post_author) %>%
        filter(n>1) %>% 
        summarize(multiple_posts = length(n))
n_multiple_responses <- merged %>% 
        filter(., !is.na(response_author)) %>%
        group_by(post_year) %>% 
        count(response_author) %>%
        filter(n > 1) %>% 
        summarize(multiple_responses = length(n))
n_self_response <- merged %>% 
        filter(., !is.na(response_author)) %>%
        mutate(self_response_numeric = ifelse(self_response, 1, 0)) %>%
        group_by(post_author, post_year) %>%
        summarize(self_responses_by_poster =  sum(self_response)) %>%
        filter(self_responses_by_poster > 0) %>%
        group_by(post_year) %>%
        summarize(n_with_some_self_responses = length(self_responses_by_poster))
table1 <- table1_init %>% 
        mutate(multiple_posts = round(100 * n_multiple_posts$multiple_posts 
                                      / n_posters, 2),
               multiple_responses = round(100 * n_multiple_responses$multiple_responses 
                                          / n_responders, 2),
               self_responses = round(100 * n_self_response$n_with_some_self_responses
                                      / n_posters, 2)
               ) %>%
        select(post_year, n_contributors, n_posters, n_responders, 
               multiple_posts, multiple_responses, self_responses)
knitr::kable(table1, 
             align='l',
             col.names=c("Year", "Contributors", "Posters", "Responders", 
                         "Multiple Posts", "Multiple Responses", "Posters with Self Responses"))
```

## Table 2. Descriptive Statistics of Posts per Poster and Responses per Responder

```{r table2, include=TRUE, echo=FALSE}
stats_posters <- merged %>% 
        group_by(post_year) %>% 
        count(post_author) %>% 
        summarize(mean_posts = round(mean(n), 2),
                  sd_posts = round(sd(n), 2),
                  median_posts = median(n),
                  min_posts = min(n),
                  max_posts = max(n)
                  )
stats_responders <- merged %>% 
        filter(., !is.na(response_author)) %>%
        group_by(post_year) %>% 
        count(response_author) %>% 
        summarize(mean_responses = round(mean(n), 2),
                  sd_responses = round(sd(n), 2),
                  median_responses = median(n),
                  min_responses = min(n),
                  max_responses = max(n)
                  )
table2 <- stats_posters %>%
        full_join(stats_responders, by="post_year")
knitr::kable(table2, 
             align='l',
             col.names=c("Year", "Mean", "SD", "Median", "Min", "Max",
                         "Mean", "SD", "Median", "Min", "Max"))
```

## Table 3. Content Interaction by Posts, Threads, and Responses

```{r table3, include=TRUE, echo=FALSE}
## have to subtract 1 to account for NA rows for n_threads and n_responses
table3 <- merged %>% 
        group_by(post_year) %>% 
        summarize(n_posts = length(unique(post_id)),
                  n_threads = length(unique(thread_id)) - 1,
                  n_responses = length(unique(response_id)) - 1,
                  n_nonzero = n_posts - length(which(is.na(response_text))),
                  words_per_post = round(mean(post_word_count), 2),
                  words_per_response = round(mean(response_word_count, na.rm=TRUE), 2)
                  ) %>%
        mutate(response_rate = round((100 * n_nonzero / n_posts), 2),
               responses_per_thread = round((n_responses / n_threads), 2)
               ) %>%
        select(post_year, n_posts, n_threads, n_responses, 
               response_rate, responses_per_thread, words_per_post, words_per_response,
               -n_nonzero)
knitr::kable(table3, 
             align='l',
             col.names=c("Year", "Posts", "Threads", "Responses", "Response Rate",
                         "Responses per Thread", "Words per Post", "Words per Response"))
```

## Table 4. Descriptive Statistics of Voting Scores of Posts and Responses

```{r table4, include=TRUE, echo=FALSE}
post_voting <- merged %>% 
        distinct(post_id, .keep_all=TRUE) %>%
        group_by(post_year) %>%
        summarize(mean_post_voting = round(mean(post_voting_score), 2),
                  sd_post_voting = round(sd(post_voting_score), 2),
                  median_post_voting = median(post_voting_score),
                  min_post_voting = min(post_voting_score),
                  max_post_voting = max(post_voting_score)
                  )
response_voting <- merged %>% 
        filter(., !is.na(response_id)) %>%
        distinct(response_id, .keep_all=TRUE) %>%
        group_by(post_year) %>%
        summarize(mean_response_voting = round(mean(response_voting_score, 
                                                    na.rm=TRUE), 2),
                  sd_response_voting = round(sd(response_voting_score, na.rm=TRUE), 2),
                  median_response_voting= median(response_voting_score, na.rm=TRUE),
                  min_response_voting = min(response_voting_score, na.rm=TRUE),
                  max_response_voting = max(response_voting_score, na.rm=TRUE)
                  )
table4 <- post_voting %>%
        full_join(response_voting, by="post_year")
knitr::kable(table4, 
             align='l',
             col.names=c("Year", "Mean", "SD", "Median", "Min", "Max",
                         "Mean", "SD", "Median", "Min", "Max"))
```

## Table 5. Social Interaction: Network Statistics by Year

```{r table5, include=TRUE, echo=FALSE}
## retrieve the name of the parent author
merged2 <- merged %>%
        filter(parent_id %in% c
               (posts$post_id, responses$thread_id, responses$response_id)) %>%
        mutate(parent_author = ifelse(parent_id %in% merged$post_id,
                                      post_author,
                                      response_author
                                      )
               )

## create edgelist and then the network graph
network_graph <- merged2 %>% 
        select(response_author, parent_author) %>%
        as.matrix() %>%
        graph_from_edgelist(directed=TRUE) %>% 
        set_vertex_attr(name='degree', value=degree(., mode='total', loops=FALSE))
#summary(network_graph)

network_graph16 <- merged2 %>% 
        filter(post_year==2016) %>%
        select(response_author, parent_author) %>%
        as.matrix() %>%
        graph_from_edgelist(directed=TRUE) %>% 
        set_vertex_attr(name='degree', value=degree(., mode='total', loops=FALSE))
#summary(network_graph16)

network_graph17 <- merged2 %>% 
        filter(post_year==2017) %>%
        select(response_author, parent_author) %>%
        as.matrix() %>%
        graph_from_edgelist(directed=TRUE) %>% 
        set_vertex_attr(name='degree', value=degree(., mode='total', loops=FALSE))
#summary(network_graph17)

network_graph18 <- merged2 %>% 
        filter(post_year==2018) %>%
        select(response_author, parent_author) %>%
        as.matrix() %>%
        graph_from_edgelist(directed=TRUE) %>% 
        set_vertex_attr(name='degree', value=degree(., mode='total', loops=FALSE))
#summary(network_graph18)

network_graph19 <- merged2 %>% 
        filter(post_year==2019) %>%
        select(response_author, parent_author) %>%
        as.matrix() %>%
        graph_from_edgelist(directed=TRUE) %>% 
        set_vertex_attr(name='degree', value=degree(., mode='total', loops=FALSE))
#summary(network_graph19)

year2016 <- c(length(V(network_graph16)),
         gsize(network_graph16),
         round(transitivity(network_graph16, "global") * 100, 2),
         round(reciprocity(network_graph16, "global") * 100, 2)
         )
year2017 <- c(length(V(network_graph17)),
         gsize(network_graph17),
         round(transitivity(network_graph17, "global") * 100, 2),
         round(reciprocity(network_graph17, "global") * 100, 2)
         )
year2018 <- c(length(V(network_graph18)),
         gsize(network_graph18),
         round(transitivity(network_graph18, "global") * 100, 2),
         round(reciprocity(network_graph18, "global") * 100, 2)
         )
year2019 <- c(length(V(network_graph19)),
         gsize(network_graph19),
         round(transitivity(network_graph19, "global") * 100, 2),
         round(reciprocity(network_graph19, "global") * 100, 2)
         )
table5 <- year2016 %>%
        rbind(year2017) %>%
        rbind(year2018) %>%
        rbind(year2019) %>%
        as.data.frame() %>%
        rownames_to_column()
colnames(table5) <- c("year", "nodes", "edges", "transitivity", "reciprocity")
table5$year <- c(2016, 2017, 2018, 2019)

table5 <- table5 %>%
        mutate(mean = c(round(mean(vertex_attr(network_graph16, 'degree')), 2), 
                        round(mean(vertex_attr(network_graph17, 'degree')), 2),
                        round(mean(vertex_attr(network_graph18, 'degree')), 2),
                        round(mean(vertex_attr(network_graph19, 'degree')), 2)
                        ),
               sd = c(round(sd(vertex_attr(network_graph16, 'degree')), 2),
                      round(sd(vertex_attr(network_graph17, 'degree')), 2), 
                      round(sd(vertex_attr(network_graph18, 'degree')), 2), 
                      round(sd(vertex_attr(network_graph19, 'degree')), 2)
                      ),
               median = c(median(vertex_attr(network_graph16, 'degree')), 
                        median(vertex_attr(network_graph17, 'degree')),
                        median(vertex_attr(network_graph18, 'degree')),
                        median(vertex_attr(network_graph19, 'degree'))
                        ),
               min = c(min(vertex_attr(network_graph16, 'degree')), 
                        min(vertex_attr(network_graph17, 'degree')),
                        min(vertex_attr(network_graph18, 'degree')),
                        min(vertex_attr(network_graph19, 'degree'))
                        ),
               max = c(max(vertex_attr(network_graph16, 'degree')), 
                        max(vertex_attr(network_graph17, 'degree')),
                        max(vertex_attr(network_graph18, 'degree')),
                        max(vertex_attr(network_graph19, 'degree'))
                        )
               )
knitr::kable(table5, 
             align='l',
             col.names=c("Year", "Nodes", "Edges", "Transitivity", "Reciprocity",
                         "Mean", "SD", "Median", "Min", "Max"))
```

## Table 6. High-Mutuality Threads

```{r, include=TRUE, echo=FALSE}
n_orig_poster_self <- length(which(merged$self_response))
p_orig_poster_self <- round(100 * n_orig_poster_self / nrow(merged), 2)

paste0("There are ", n_orig_poster_self, " self-responses (", p_orig_poster_self,  "%) written by original posters.")
```

We theorized *high-mutuality threads* as those posts with at least **10 responses** and where the original poster contributed not just a single response but also did not overly dominate the conversation (i.e., **20-50% self-responses**). Table 6 depicts a summary of these high-mutuality threads in terms of threads with self-responses.

```{r, include=TRUE, echo=FALSE}
mutuals2016 <- merged %>% 
        distinct(post_id, .keep_all = TRUE) %>%
        filter(post_year==2016,
               n_responses >= 10,
               p_self_responses >= 20,
               p_self_responses <= 50)
mutuals2017 <- merged %>% 
        distinct(post_id, .keep_all = TRUE) %>%
        filter(post_year==2017,
               n_responses >= 10,
               p_self_responses >= 20,
               p_self_responses <= 50)
mutuals2018 <- merged %>% 
        distinct(post_id, .keep_all = TRUE) %>%
        filter(post_year==2018,
               n_responses >= 10,
               p_self_responses >= 20,
               p_self_responses <= 50)
mutuals2019 <- merged %>% 
        distinct(post_id, .keep_all = TRUE) %>%
        filter(post_year==2019,
               n_responses >= 10,
               p_self_responses >= 20,
               p_self_responses <= 50)

table6v2016 <- c(nrow(mutuals2016), round(100 * nrow(mutuals2016) / table3$n_posts[1]),
                 summary(mutuals2016$n_responses), sd(mutuals2016$n_responses), 
                 summary(mutuals2016$p_self_responses), sd(mutuals2016$p_self_responses))
table6v2017 <- c(nrow(mutuals2017), round(100 * nrow(mutuals2017) / table3$n_posts[2]),
                 summary(mutuals2017$n_responses), sd(mutuals2017$n_responses), 
                 summary(mutuals2017$p_self_responses), sd(mutuals2017$p_self_responses))
table6v2018 <- c(nrow(mutuals2018), round(100 * nrow(mutuals2018) / table3$n_posts[3]),
                 summary(mutuals2018$n_responses), sd(mutuals2018$n_responses), 
                 summary(mutuals2018$p_self_responses), sd(mutuals2018$p_self_responses))
table6v2019 <- c(nrow(mutuals2019), round(100 * nrow(mutuals2019) / table3$n_posts[4]),
                 summary(mutuals2019$n_responses), sd(mutuals2019$n_responses), 
                 summary(mutuals2019$p_self_responses), sd(mutuals2019$p_self_responses))

table6 <- table6v2016 %>%
        rbind(table6v2017) %>%
        rbind(table6v2018) %>%
        rbind(table6v2019) %>%
        as.data.frame() %>%
        rownames_to_column() %>%
        select(-`1st Qu.`, -`3rd Qu.`, -`1st Qu..1`, -`3rd Qu..1`) %>%
        rename(year = rowname, self_reponse_total = V1, self_response_prop = V2,
               n_mean = Mean, n_median = Median, n_min = `Min.`, n_max = `Max.`, n_sd = V9,
               p_mean = `Mean.1`, p_median = `Median.1`, p_min = `Min..1`, p_max = `Max..1`, p_sd = V16
               ) %>%
        select(year, self_reponse_total, self_response_prop, n_mean, n_sd, n_median, n_min, n_max,
               p_mean, p_sd, p_median, p_min, p_max)
table6$year <- c(2016, 2017, 2018, 2019)

knitr::kable(table6, 
             align='l',
             col.names=c("Year", "Threads n", "Threads p",
                         "Mean n", "SD n", "Median n", "min n", "max n",
                         "Mean p", "SD p", "Median p", "min p", "max p"))

```

# Sample posts for qualitative content analysis

Finally, we took a sample of 100 posts from the *high-mutuality threads* for further examination.

```{r sample, include=FALSE}
sample_year <- 2016
sample_size <- 100

set.seed(11182019)
sample_ids <- posts %>% 
        filter(post_year==sample_year) %>% 
        pull(post_id) %>% 
        sample(size=sample_size)

posts_sample <- posts %>% filter(post_id %in% sample_ids)
#posts_sample %>% write.csv("data/r-teachers-posts-sample.csv", row.names=FALSE)
```

# Version/dependencies

```{r, session-info}
sessionInfo()
```